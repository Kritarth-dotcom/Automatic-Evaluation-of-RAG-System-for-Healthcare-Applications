{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6771c866-14e1-4b84-b31b-aec1bd36228e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ragas in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.7)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.21.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (1.26.4)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (0.12.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (2.12.3)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (1.6.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (5.6.3)\n",
      "Requirement already satisfied: typer in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (0.9.4)\n",
      "Requirement already satisfied: rich in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (13.8.0)\n",
      "Requirement already satisfied: openai>=1.0.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (1.109.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (4.67.1)\n",
      "Requirement already satisfied: instructor in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (1.0.0)\n",
      "Requirement already satisfied: gitpython in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (3.1.43)\n",
      "Requirement already satisfied: pillow>=10.4.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (12.0.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (3.2.1)\n",
      "Requirement already satisfied: scikit-network in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (0.33.3)\n",
      "Requirement already satisfied: langchain in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (1.0.2)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (1.0.0)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (0.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core->ragas) (0.4.37)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core->ragas) (24.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core->ragas) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core->ragas) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core->ragas) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (3.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.0.0->ragas) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.0.0->ragas) (0.11.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.0.0->ragas) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.0.0->ragas) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken->ragas) (2025.10.23)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.16.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (2.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->ragas) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython->ragas) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->ragas) (5.0.1)\n",
      "Requirement already satisfied: docstring-parser<0.16,>=0.15 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor->ragas) (0.15)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->ragas) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->ragas) (2.18.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer->ragas) (8.1.7)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->ragas) (0.1.2)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->ragas) (1.0.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain->ragas) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain->ragas) (1.0.1)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain->ragas) (0.2.9)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain->ragas) (1.11.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community->ragas) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community->ragas) (2.0.43)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community->ragas) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community->ragas) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community->ragas) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas) (1.1.1)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community->ragas) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.7.3 in c:\\users\\krita\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-network->ragas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install --user ragas langchain-openai pandas datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b200f05-14bf-4ac8-8327-193352a121cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Model Configuration (Ragas)\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "# Ragas specific imports\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    # Independent of Ground Truth (Reference-Free)\n",
    "    context_precision,      \n",
    "    answer_relevancy,       \n",
    "    faithfulness,           \n",
    "    \n",
    "    # Dependent on Ground Truth (Reference-Required)\n",
    "    context_recall,         \n",
    "    context_entity_recall,  \n",
    "    answer_correctness,     \n",
    "    answer_similarity       \n",
    ")\n",
    "\n",
    "# Ragas 1.0+ uses Langchain models\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings \n",
    "\n",
    "from ragas.exceptions import RagasException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b0fe27-92f4-4d01-b205-2c4a9f08e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- AZURE CONFIGURATION (!!! REPLACE PLACEHOLDERS BELOW !!!) ---\n",
    "# ⚠️ IMPORTANT: Replace with your actual key\n",
    "AZURE_API_KEY = \"<YOUR_AZURE_OPENAI\" \n",
    "AZURE_ENDPOINT = \"https://<YOUR_AZURE_OPENAI_ENDPOINT>.openai.azure.com/\"\n",
    "AZURE_CHAT_DEPLOYMENT = \"gpt-4o-08-06\" # Model used for evaluation logic (e.g., faithfulness, relevancy)\n",
    "AZURE_EMBEDDINGS_DEPLOYMENT = \"text_embedding_ada_002\" # Model used for semantic metrics (e.g., similarity)\n",
    "AZURE_API_VERSION = \"2024-12-01-preview\" \n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# Set environment variable for Langchain/Ragas to pick up the key\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6018f90-69cf-4f27-8edc-c6d8ac98bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ragas Chat LLM initialized successfully!\n",
      "✅ Ragas Embeddings LLM initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ragas LLM (for the main evaluation)\n",
    "try:\n",
    "    ragas_llm = AzureChatOpenAI(\n",
    "        api_key=AZURE_API_KEY, \n",
    "        azure_endpoint=AZURE_ENDPOINT,\n",
    "        deployment_name=AZURE_CHAT_DEPLOYMENT, \n",
    "        api_version=AZURE_API_VERSION,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    print(\"✅ Ragas Chat LLM initialized successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error initializing Ragas AzureChatOpenAI LLM: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Initialize Ragas Embeddings LLM\n",
    "try:\n",
    "    ragas_embeddings_llm = AzureOpenAIEmbeddings(\n",
    "        api_key=AZURE_API_KEY,\n",
    "        azure_endpoint=AZURE_ENDPOINT,\n",
    "        deployment=AZURE_EMBEDDINGS_DEPLOYMENT, \n",
    "        openai_api_version=AZURE_API_VERSION,\n",
    "        model=AZURE_EMBEDDINGS_DEPLOYMENT\n",
    "    )\n",
    "    print(\"✅ Ragas Embeddings LLM initialized successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error initializing Ragas AzureOpenAIEmbeddings LLM: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fbdef74-6ff7-4413-8838-85bdb03d982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation on: ['faithfulness', 'answer_relevancy', 'context_precision', 'context_recall', 'context_entity_recall', 'answer_correctness', 'answer_similarity']\n"
     ]
    }
   ],
   "source": [
    "# Metrics to run (7 Core Functional Metrics)\n",
    "REQUESTED_METRICS = [\n",
    "    # Reference-Free Metrics (Independent of Ground Truth)\n",
    "    faithfulness,         # Measures how factually accurate the generated answer is based on the context.\n",
    "    answer_relevancy,     # Measures how relevant the generated answer is to the question.\n",
    "    context_precision,    # Measures how relevant the retrieved context chunks are to answering the question.\n",
    "    \n",
    "    # Reference-Required Metrics (Dependent on Ground Truth)\n",
    "    context_recall,       # Measures the ability of the retrieval system to surface all necessary information.\n",
    "    context_entity_recall,# Measures recall based on entities present in the ground truth.\n",
    "    answer_correctness,   # Measures how close the generated answer is to the ground truth.\n",
    "    answer_similarity     # Measures the semantic similarity between the generated answer and ground truth.\n",
    "]\n",
    "\n",
    "print(f\"Running evaluation on: {[m.name for m in REQUESTED_METRICS]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974d85a0-f008-4dd8-9081-cc665811b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset_iteratively(json_file_path):\n",
    "    \"\"\"\n",
    "    Load data (as a single JSON list or JSONL) and evaluate all samples \n",
    "    in the JSON file one by one (iteratively).\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from: {json_file_path}\")\n",
    "    \n",
    "    if not os.path.exists(json_file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {json_file_path}\")\n",
    "    \n",
    "    all_results_list = []\n",
    "    data_list = []\n",
    "    \n",
    "    # Load data robustly to handle single JSON list or JSONL\n",
    "    try:\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "            full_content = f.read().strip()\n",
    "            \n",
    "            if not full_content:\n",
    "                print(\"File is empty.\")\n",
    "                return None\n",
    "                \n",
    "            if full_content.startswith('['):\n",
    "                data_list = json.loads(full_content)\n",
    "                print(f\"Loaded {len(data_list)} samples from a single JSON list format.\")\n",
    "            else:\n",
    "                for line in full_content.splitlines():\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        data_list.append(json.loads(line))\n",
    "                print(f\"Loaded {len(data_list)} samples from JSONL format.\")\n",
    "                \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Fatal Error: Could not parse JSON file. Check for formatting errors. {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during file loading: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not data_list:\n",
    "        print(\"No valid data loaded for evaluation.\")\n",
    "        return None\n",
    "        \n",
    "    for line_num, raw_data in enumerate(data_list, 1):\n",
    "        \n",
    "        if not isinstance(raw_data, dict):\n",
    "            print(f\"Warning: Skipping item {line_num}. Expected dict, got {type(raw_data)}.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing Sample {line_num} / {len(data_list)}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        try:\n",
    "            # 2. Transform the single sample into Ragas format\n",
    "            sample_dict = {}\n",
    "            sample_dict['question'] = raw_data.get('question', '')\n",
    "            sample_dict['answer'] = raw_data.get('answer', '')\n",
    "            \n",
    "            # Handle context: If it's a list already, use it. If it's a string, wrap it.\n",
    "            context_data = raw_data.get('context')\n",
    "            if isinstance(context_data, list):\n",
    "                sample_dict['contexts'] = context_data\n",
    "            elif pd.notna(context_data) and context_data is not None:\n",
    "                # Assuming context is a single string which Ragas expects as a list of strings\n",
    "                sample_dict['contexts'] = [str(context_data)]\n",
    "            else:\n",
    "                 sample_dict['contexts'] = []\n",
    "\n",
    "            # 'truth' maps to 'reference' (str) and 'ground_truths' (list[str])\n",
    "            truth_str = raw_data.get('truth', '')\n",
    "            sample_dict['reference'] = truth_str\n",
    "            sample_dict['ground_truths'] = [truth_str]\n",
    "            \n",
    "            # Create a single-row Dataset\n",
    "            sample_dataset = Dataset.from_list([sample_dict]) \n",
    "\n",
    "            # 3. Run Ragas evaluation on the single sample\n",
    "            result = evaluate(\n",
    "                sample_dataset,\n",
    "                metrics=REQUESTED_METRICS,\n",
    "                llm=ragas_llm,\n",
    "                embeddings=ragas_embeddings_llm,\n",
    "            )\n",
    "            \n",
    "            print(f\"Sample {line_num} Scores:\")\n",
    "            single_row_scores = result.to_pandas().iloc[0].to_dict()\n",
    "            for metric in [m.name for m in REQUESTED_METRICS]:\n",
    "                score = single_row_scores.get(metric)\n",
    "                if score is not None:\n",
    "                    print(f\"  {metric.replace('_', ' ').title():<25}: {score:.3f}\")\n",
    "\n",
    "            # 4. Store the result \n",
    "            all_results_list.append(result.to_pandas())\n",
    "\n",
    "        except Exception as e:\n",
    "            question_preview = raw_data.get('question', 'N/A')\n",
    "            # Print a warning but continue processing other samples\n",
    "            print(f\"Warning: Failed to evaluate sample at index {line_num}: {e}\")\n",
    "            print(f\"  Question: {question_preview[:100]}...\")\n",
    "    \n",
    "    if not all_results_list:\n",
    "        print(\"No data processed, skipping evaluation.\")\n",
    "        return None\n",
    "    \n",
    "    # 5. Combine all 1-row DataFrames into a single DataFrame\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Combining all results...\")\n",
    "    print(\"=\"*50)\n",
    "    final_results_df = pd.concat(all_results_list, ignore_index=True)\n",
    "    \n",
    "    return final_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c64793b2-7dd1-414a-8a40-c1094527049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results_df, output_file=\"evaluation_results.json\"):\n",
    "    \"\"\"Save detailed results DataFrame to JSON file\"\"\"\n",
    "    if results_df is None: return\n",
    "    # Filter out non-JSON serializable objects (like list of contexts/ground_truths) for clean export\n",
    "    export_df = results_df.copy()\n",
    "    \n",
    "    # Ragas uses the 'contexts' and 'ground_truths' columns which contain lists/objects.\n",
    "    records = export_df.to_dict('records')\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Detailed results saved to {output_file}\")\n",
    "\n",
    "def export_to_csv(results_df, csv_file=\"evaluation_results.csv\"):\n",
    "    \"\"\"Export results DataFrame to CSV for easier analysis\"\"\"\n",
    "    if results_df is None: return\n",
    "    \n",
    "    # Convert list columns to strings for CSV compatibility\n",
    "    csv_df = results_df.copy()\n",
    "    for col in ['contexts', 'ground_truths']:\n",
    "        if col in csv_df.columns:\n",
    "            csv_df[col] = csv_df[col].apply(lambda x: '|'.join(x) if isinstance(x, list) else x)\n",
    "            \n",
    "    csv_df.to_csv(csv_file, index=False, encoding='utf-8')\n",
    "    print(f\"Results exported to {csv_file}\")\n",
    "\n",
    "def create_summary_statistics(results_df, summary_file=\"evaluation_summary.json\"):\n",
    "    \"\"\"Create summary statistics from results DataFrame\"\"\"\n",
    "    if results_df is None: return {}\n",
    "        \n",
    "    metric_names = [m.name for m in REQUESTED_METRICS]\n",
    "    enhanced_summary = {}\n",
    "    \n",
    "    for metric_name in metric_names: \n",
    "        if metric_name in results_df.columns:\n",
    "            # Drop NaN scores, which occur if an evaluation fails for a specific metric on a sample\n",
    "            scores = results_df[metric_name].dropna().tolist() \n",
    "            if scores:\n",
    "                enhanced_summary[metric_name] = {\n",
    "                    'mean': round(np.mean(scores), 3), \n",
    "                    'min': round(min(scores), 3),\n",
    "                    'max': round(max(scores), 3),\n",
    "                    'count': len(scores),\n",
    "                    'std_dev': round(np.std(scores), 3) if len(scores) > 1 else 0\n",
    "                }\n",
    "            else:\n",
    "                enhanced_summary[metric_name] = {'mean': 0, 'count': 0}\n",
    "    \n",
    "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(enhanced_summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Summary statistics saved to {summary_file}\")\n",
    "    return enhanced_summary \n",
    "\n",
    "def print_quick_summary(summary_dict):\n",
    "    \"\"\"Print a quick summary (mean scores) to console from the summary dict\"\"\"\n",
    "    if not summary_dict: return\n",
    "        \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"RAGAS QUICK SUMMARY (Mean Scores)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for metric, stats in summary_dict.items():\n",
    "        print(f\"{metric.replace('_', ' ').title():<25}: {stats['mean']:.3f}\")\n",
    "    \n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cbade6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iterative evaluation for: 2_sample_test_qa_eval.jsonl\n",
      "Loading data from: 2_sample_test_qa_eval.jsonl\n",
      "Loaded 3 samples from JSONL format.\n",
      "\n",
      "==================================================\n",
      "Processing Sample 1 / 3\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0691cbd3fb7a48fd937ca6e270a2d7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 Scores:\n",
      "  Faithfulness             : 0.917\n",
      "  Answer Relevancy         : 0.975\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.329\n",
      "  Answer Similarity        : 0.964\n",
      "\n",
      "==================================================\n",
      "Processing Sample 2 / 3\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7578fba7e842b08b7d5538860b324c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.974\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.370\n",
      "  Answer Similarity        : 0.959\n",
      "\n",
      "==================================================\n",
      "Processing Sample 3 / 3\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b859473f418745a29d23113dee7c021d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.955\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.579\n",
      "  Answer Similarity        : 0.983\n",
      "\n",
      "==================================================\n",
      "Combining all results...\n",
      "==================================================\n",
      "Detailed results saved to evaluation_results.json\n",
      "Results exported to evaluation_results.csv\n",
      "Summary statistics saved to evaluation_summary.json\n",
      "\n",
      "==================================================\n",
      "RAGAS QUICK SUMMARY (Mean Scores)\n",
      "==================================================\n",
      "Faithfulness             : 0.972\n",
      "Answer Relevancy         : 0.968\n",
      "Context Precision        : 1.000\n",
      "Context Recall           : 1.000\n",
      "Context Entity Recall    : 0.833\n",
      "Answer Correctness       : 0.426\n",
      "Answer Similarity        : 0.969\n",
      "==================================================\n",
      "\n",
      " ✅ Evaluation completed successfully!\n",
      "Total successful samples evaluated: 3\n",
      "\n",
      "First 3 results preview:\n",
      "================================================================================\n",
      "\n",
      "Sample 1:\n",
      "Question (Start): N/A...\n",
      "Faithfulness: 0.917\n",
      "Answer Relevancy: 0.975\n",
      "Context Precision: 1.000\n",
      "Context Recall: 1.000\n",
      "Context Entity Recall: 0.500\n",
      "Answer Correctness: 0.329\n",
      "Answer Similarity: 0.964\n",
      "----------------------------------------\n",
      "\n",
      "Sample 2:\n",
      "Question (Start): N/A...\n",
      "Faithfulness: 1.000\n",
      "Answer Relevancy: 0.974\n",
      "Context Precision: 1.000\n",
      "Context Recall: 1.000\n",
      "Context Entity Recall: 1.000\n",
      "Answer Correctness: 0.370\n",
      "Answer Similarity: 0.959\n",
      "----------------------------------------\n",
      "\n",
      "Sample 3:\n",
      "Question (Start): N/A...\n",
      "Faithfulness: 1.000\n",
      "Answer Relevancy: 0.955\n",
      "Context Precision: 1.000\n",
      "Context Recall: 1.000\n",
      "Context Entity Recall: 1.000\n",
      "Answer Correctness: 0.579\n",
      "Answer Similarity: 0.983\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results_df = None\n",
    "summary_stats = {}\n",
    "\n",
    "json_file_path = \"2_sample_test_qa_eval.jsonl\"\n",
    "\n",
    "try:\n",
    "    print(f\"Starting iterative evaluation for: {json_file_path}\")\n",
    "    \n",
    "    results_df = evaluate_dataset_iteratively(json_file_path)\n",
    "    \n",
    "    if results_df is not None and not results_df.empty:\n",
    "        # Save all results\n",
    "        save_results(results_df)\n",
    "        export_to_csv(results_df)\n",
    "        \n",
    "        # Create and print summary\n",
    "        summary_stats = create_summary_statistics(results_df)\n",
    "        print_quick_summary(summary_stats)\n",
    "        \n",
    "        print(\"\\n ✅ Evaluation completed successfully!\")\n",
    "        print(f\"Total successful samples evaluated: {len(results_df)}\")\n",
    "\n",
    "        print(\"\\nFirst 3 results preview:\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Display the start of the question in the preview\n",
    "        for i in range(min(3, len(results_df))):\n",
    "            result = results_df.iloc[i]\n",
    "            print(f\"\\nSample {i+1}:\")\n",
    "            \n",
    "            # Get the question and limit it to the first 100 characters for a preview\n",
    "            question_preview = result.get('question', 'N/A')\n",
    "            print(f\"Question (Start): {question_preview[:100]}...\")\n",
    "            \n",
    "            for metric in REQUESTED_METRICS:\n",
    "                score = result.get(metric.name, 'N/A')\n",
    "                if isinstance(score, float):\n",
    "                    score = f\"{score:.3f}\"\n",
    "                print(f\"{metric.name.replace('_', ' ').title()}: {score}\")\n",
    "            \n",
    "            print(\"-\" * 40)\n",
    "\n",
    "    else:\n",
    "        print(\"Evaluation did not produce any successful results.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ File not found: {e}\")\n",
    "    print(f\"Please check if the file exists at: {json_file_path}\")\n",
    "\n",
    "except RagasException as e:\n",
    "    print(f\"\\n❌ [RAGAS ERROR] {e}\")\n",
    "    print(\"Evaluation halted. Check API keys, endpoints, and rate limits.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Unexpected error in main execution: {e}\")\n",
    "    print(f\"Full traceback:\\n{traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a616213b-88c4-4938-ab20-122ddbd76a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iterative evaluation for: 200_sample_test_qa_eval.jsonl\n",
      "Loading data from: 200_sample_test_qa_eval.jsonl\n",
      "Loaded 200 samples from JSONL format.\n",
      "\n",
      "==================================================\n",
      "Processing Sample 1 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:45<00:00,  6.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 Scores:\n",
      "  Faithfulness             : 0.923\n",
      "  Answer Relevancy         : 0.975\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.429\n",
      "  Answer Similarity        : 0.964\n",
      "\n",
      "==================================================\n",
      "Processing Sample 2 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  29%|██▊       | 2/7 [00:08<00:18,  3.74s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.983\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.311\n",
      "  Answer Similarity        : 0.959\n",
      "\n",
      "==================================================\n",
      "Processing Sample 3 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:18,  3.07s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:42<00:00,  6.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.955\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.579\n",
      "  Answer Similarity        : 0.983\n",
      "\n",
      "==================================================\n",
      "Processing Sample 4 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 4 Scores:\n",
      "  Faithfulness             : 0.727\n",
      "  Answer Relevancy         : 0.895\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.227\n",
      "  Answer Similarity        : 0.907\n",
      "\n",
      "==================================================\n",
      "Processing Sample 5 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 5 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.924\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.558\n",
      "  Answer Similarity        : 0.969\n",
      "\n",
      "==================================================\n",
      "Processing Sample 6 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:53<00:00,  7.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 6 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.965\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.312\n",
      "  Answer Similarity        : 0.961\n",
      "\n",
      "==================================================\n",
      "Processing Sample 7 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:17,  2.92s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:50<00:00,  7.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 7 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.929\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.350\n",
      "  Answer Similarity        : 0.954\n",
      "\n",
      "==================================================\n",
      "Processing Sample 8 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 8 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.899\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.333\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.319\n",
      "  Answer Similarity        : 0.901\n",
      "\n",
      "==================================================\n",
      "Processing Sample 9 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  29%|██▊       | 2/7 [00:08<00:23,  4.69s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:45<00:00,  6.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 9 Scores:\n",
      "  Faithfulness             : 0.941\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.489\n",
      "  Answer Similarity        : 0.957\n",
      "\n",
      "==================================================\n",
      "Processing Sample 10 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:20,  3.44s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 10 Scores:\n",
      "  Faithfulness             : 0.950\n",
      "  Answer Relevancy         : 0.962\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.435\n",
      "  Answer Similarity        : 0.957\n",
      "\n",
      "==================================================\n",
      "Processing Sample 11 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 11 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.984\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.234\n",
      "  Answer Similarity        : 0.936\n",
      "\n",
      "==================================================\n",
      "Processing Sample 12 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:44<00:00,  6.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 12 Scores:\n",
      "  Faithfulness             : 0.909\n",
      "  Answer Relevancy         : 0.972\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.200\n",
      "  Answer Correctness       : 0.612\n",
      "  Answer Similarity        : 0.948\n",
      "\n",
      "==================================================\n",
      "Processing Sample 13 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  29%|██▊       | 2/7 [00:08<00:21,  4.32s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:43<00:00,  6.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 13 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.881\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.313\n",
      "  Answer Similarity        : 0.937\n",
      "\n",
      "==================================================\n",
      "Processing Sample 14 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:16,  2.83s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:39<00:00,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 14 Scores:\n",
      "  Faithfulness             : 0.900\n",
      "  Answer Relevancy         : 0.989\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.371\n",
      "  Answer Similarity        : 0.937\n",
      "\n",
      "==================================================\n",
      "Processing Sample 15 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:16,  2.70s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:37<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 15 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.999\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.400\n",
      "  Answer Correctness       : 0.462\n",
      "  Answer Similarity        : 0.926\n",
      "\n",
      "==================================================\n",
      "Processing Sample 16 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:16,  2.80s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:34<00:00,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 16 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.871\n",
      "  Answer Similarity        : 0.985\n",
      "\n",
      "==================================================\n",
      "Processing Sample 17 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:16,  2.68s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:33<00:00,  4.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 17 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.740\n",
      "  Answer Similarity        : 0.959\n",
      "\n",
      "==================================================\n",
      "Processing Sample 18 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  29%|██▊       | 2/7 [00:08<00:21,  4.33s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:44<00:00,  6.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 18 Scores:\n",
      "  Faithfulness             : 0.941\n",
      "  Answer Relevancy         : 0.978\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.570\n",
      "  Answer Similarity        : 0.946\n",
      "\n",
      "==================================================\n",
      "Processing Sample 19 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:37<00:00,  5.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 19 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.912\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.738\n",
      "  Answer Similarity        : 0.952\n",
      "\n",
      "==================================================\n",
      "Processing Sample 20 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  43%|████▎     | 3/7 [00:15<00:18,  4.75s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  5.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 20 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.853\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.326\n",
      "  Answer Similarity        : 0.930\n",
      "\n",
      "==================================================\n",
      "Processing Sample 21 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:47<00:00,  6.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 21 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.459\n",
      "  Answer Similarity        : 0.935\n",
      "\n",
      "==================================================\n",
      "Processing Sample 22 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:47<00:00,  6.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 22 Scores:\n",
      "  Faithfulness             : 0.857\n",
      "  Answer Relevancy         : 0.973\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.487\n",
      "  Answer Similarity        : 0.948\n",
      "\n",
      "==================================================\n",
      "Processing Sample 23 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:40<00:00,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 23 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.860\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.370\n",
      "  Answer Similarity        : 0.907\n",
      "\n",
      "==================================================\n",
      "Processing Sample 24 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:40<00:00,  5.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 24 Scores:\n",
      "  Faithfulness             : 0.818\n",
      "  Answer Relevancy         : 0.919\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.714\n",
      "  Answer Correctness       : 0.763\n",
      "  Answer Similarity        : 0.933\n",
      "\n",
      "==================================================\n",
      "Processing Sample 25 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 25 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.993\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.311\n",
      "  Answer Similarity        : 0.944\n",
      "\n",
      "==================================================\n",
      "Processing Sample 26 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  5.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 26 Scores:\n",
      "  Faithfulness             : 0.667\n",
      "  Answer Relevancy         : 0.916\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.232\n",
      "  Answer Similarity        : 0.929\n",
      "\n",
      "==================================================\n",
      "Processing Sample 27 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:40<00:00,  5.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 27 Scores:\n",
      "  Faithfulness             : 0.889\n",
      "  Answer Relevancy         : 0.956\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.477\n",
      "  Answer Similarity        : 0.909\n",
      "\n",
      "==================================================\n",
      "Processing Sample 28 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 28 Scores:\n",
      "  Faithfulness             : 0.500\n",
      "  Answer Relevancy         : 0.973\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.221\n",
      "  Answer Similarity        : 0.883\n",
      "\n",
      "==================================================\n",
      "Processing Sample 29 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:16,  2.78s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:51<00:00,  7.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 29 Scores:\n",
      "  Faithfulness             : 0.895\n",
      "  Answer Relevancy         : 0.986\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.125\n",
      "  Answer Correctness       : 0.226\n",
      "  Answer Similarity        : 0.906\n",
      "\n",
      "==================================================\n",
      "Processing Sample 30 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:04<00:24,  4.01s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 30 Scores:\n",
      "  Faithfulness             : 0.964\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.227\n",
      "  Answer Similarity        : 0.908\n",
      "\n",
      "==================================================\n",
      "Processing Sample 31 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:16,  2.81s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:47<00:00,  6.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 31 Scores:\n",
      "  Faithfulness             : 0.750\n",
      "  Answer Relevancy         : 0.000\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.083\n",
      "  Answer Correctness       : 0.234\n",
      "  Answer Similarity        : 0.936\n",
      "\n",
      "==================================================\n",
      "Processing Sample 32 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:23,  3.90s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:45<00:00,  6.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 32 Scores:\n",
      "  Faithfulness             : 0.667\n",
      "  Answer Relevancy         : 0.000\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.143\n",
      "  Answer Correctness       : 0.234\n",
      "  Answer Similarity        : 0.936\n",
      "\n",
      "==================================================\n",
      "Processing Sample 33 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:17,  2.99s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 33 Scores:\n",
      "  Faithfulness             : 0.889\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.231\n",
      "  Answer Similarity        : 0.922\n",
      "\n",
      "==================================================\n",
      "Processing Sample 34 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:59<00:00,  8.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 34 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.990\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.750\n",
      "  Answer Correctness       : 0.379\n",
      "  Answer Similarity        : 0.970\n",
      "\n",
      "==================================================\n",
      "Processing Sample 35 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:17,  2.96s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 35 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.986\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.745\n",
      "  Answer Similarity        : 0.981\n",
      "\n",
      "==================================================\n",
      "Processing Sample 36 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 36 Scores:\n",
      "  Faithfulness             : 0.750\n",
      "  Answer Relevancy         : 0.919\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.223\n",
      "  Answer Similarity        : 0.894\n",
      "\n",
      "==================================================\n",
      "Processing Sample 37 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:53<00:00,  7.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 37 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.288\n",
      "  Answer Similarity        : 0.912\n",
      "\n",
      "==================================================\n",
      "Processing Sample 38 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  6.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 38 Scores:\n",
      "  Faithfulness             : 0.600\n",
      "  Answer Relevancy         : 0.992\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.833\n",
      "  Answer Correctness       : 0.490\n",
      "  Answer Similarity        : 0.961\n",
      "\n",
      "==================================================\n",
      "Processing Sample 39 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:15,  2.58s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:42<00:00,  6.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 39 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.960\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.394\n",
      "  Answer Similarity        : 0.943\n",
      "\n",
      "==================================================\n",
      "Processing Sample 40 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:40<00:00,  5.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 40 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.855\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.539\n",
      "  Answer Similarity        : 0.955\n",
      "\n",
      "==================================================\n",
      "Processing Sample 41 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:20,  3.39s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 41 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.901\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.465\n",
      "  Answer Similarity        : 0.935\n",
      "\n",
      "==================================================\n",
      "Processing Sample 42 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:53<00:00,  7.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 42 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.954\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.587\n",
      "  Answer Similarity        : 0.936\n",
      "\n",
      "==================================================\n",
      "Processing Sample 43 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 43 Scores:\n",
      "  Faithfulness             : 0.600\n",
      "  Answer Relevancy         : 0.988\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.558\n",
      "  Answer Similarity        : 0.967\n",
      "\n",
      "==================================================\n",
      "Processing Sample 44 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:20,  3.49s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:45<00:00,  6.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 44 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.334\n",
      "  Answer Similarity        : 0.960\n",
      "\n",
      "==================================================\n",
      "Processing Sample 45 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:22,  3.80s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:42<00:00,  6.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 45 Scores:\n",
      "  Faithfulness             : 0.875\n",
      "  Answer Relevancy         : 0.995\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.406\n",
      "  Answer Similarity        : 0.958\n",
      "\n",
      "==================================================\n",
      "Processing Sample 46 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:51<00:00,  7.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 46 Scores:\n",
      "  Faithfulness             : 0.964\n",
      "  Answer Relevancy         : 0.966\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.373\n",
      "  Answer Similarity        : 0.931\n",
      "\n",
      "==================================================\n",
      "Processing Sample 47 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:43<00:00,  6.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 47 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.891\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.426\n",
      "  Answer Similarity        : 0.955\n",
      "\n",
      "==================================================\n",
      "Processing Sample 48 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:47<00:00,  6.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 48 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.600\n",
      "  Answer Correctness       : 0.408\n",
      "  Answer Similarity        : 0.966\n",
      "\n",
      "==================================================\n",
      "Processing Sample 49 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:18,  3.08s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:43<00:00,  6.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 49 Scores:\n",
      "  Faithfulness             : 0.667\n",
      "  Answer Relevancy         : 0.975\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.833\n",
      "  Answer Correctness       : 0.478\n",
      "  Answer Similarity        : 0.965\n",
      "\n",
      "==================================================\n",
      "Processing Sample 50 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:39<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 50 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.979\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.400\n",
      "  Answer Correctness       : 0.560\n",
      "  Answer Similarity        : 0.956\n",
      "\n",
      "==================================================\n",
      "Processing Sample 51 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  5.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 51 Scores:\n",
      "  Faithfulness             : 0.917\n",
      "  Answer Relevancy         : 0.948\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.329\n",
      "  Answer Similarity        : 0.940\n",
      "\n",
      "==================================================\n",
      "Processing Sample 52 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 52 Scores:\n",
      "  Faithfulness             : 0.944\n",
      "  Answer Relevancy         : 0.912\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.370\n",
      "  Answer Similarity        : 0.960\n",
      "\n",
      "==================================================\n",
      "Processing Sample 53 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:18,  3.15s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:42<00:00,  6.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 53 Scores:\n",
      "  Faithfulness             : 0.889\n",
      "  Answer Relevancy         : 0.980\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.167\n",
      "  Answer Correctness       : 0.642\n",
      "  Answer Similarity        : 0.970\n",
      "\n",
      "==================================================\n",
      "Processing Sample 54 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:43<00:00,  6.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 54 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.391\n",
      "  Answer Similarity        : 0.965\n",
      "\n",
      "==================================================\n",
      "Processing Sample 55 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:17,  2.98s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:47<00:00,  6.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 55 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.167\n",
      "  Answer Correctness       : 0.516\n",
      "  Answer Similarity        : 0.973\n",
      "\n",
      "==================================================\n",
      "Processing Sample 56 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:16,  2.77s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 56 Scores:\n",
      "  Faithfulness             : 0.950\n",
      "  Answer Relevancy         : 0.968\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.200\n",
      "  Answer Correctness       : 0.286\n",
      "  Answer Similarity        : 0.931\n",
      "\n",
      "==================================================\n",
      "Processing Sample 57 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  5.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 57 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.848\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.318\n",
      "  Answer Similarity        : 0.940\n",
      "\n",
      "==================================================\n",
      "Processing Sample 58 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  29%|██▊       | 2/7 [00:07<00:20,  4.09s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:52<00:00,  7.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 58 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.862\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.373\n",
      "  Answer Similarity        : 0.947\n",
      "\n",
      "==================================================\n",
      "Processing Sample 59 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:19,  3.21s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:52<00:00,  7.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 59 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.968\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.298\n",
      "  Answer Similarity        : 0.959\n",
      "\n",
      "==================================================\n",
      "Processing Sample 60 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:16,  2.68s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  5.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 60 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.000\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.234\n",
      "  Answer Similarity        : 0.935\n",
      "\n",
      "==================================================\n",
      "Processing Sample 61 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:04<00:25,  4.33s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:47<00:00,  6.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 61 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.994\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.470\n",
      "  Answer Similarity        : 0.934\n",
      "\n",
      "==================================================\n",
      "Processing Sample 62 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:17,  2.99s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  5.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 62 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.951\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.510\n",
      "  Answer Similarity        : 0.950\n",
      "\n",
      "==================================================\n",
      "Processing Sample 63 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:52<00:00,  7.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 63 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.942\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.290\n",
      "  Answer Similarity        : 0.928\n",
      "\n",
      "==================================================\n",
      "Processing Sample 64 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:51<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 64 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.997\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.834\n",
      "  Answer Similarity        : 0.936\n",
      "\n",
      "==================================================\n",
      "Processing Sample 65 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:06<00:39,  6.63s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:45<00:00,  6.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 65 Scores:\n",
      "  Faithfulness             : 0.933\n",
      "  Answer Relevancy         : 0.976\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.750\n",
      "  Answer Correctness       : 0.328\n",
      "  Answer Similarity        : 0.958\n",
      "\n",
      "==================================================\n",
      "Processing Sample 66 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:42<00:00,  6.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 66 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.899\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.651\n",
      "  Answer Similarity        : 0.966\n",
      "\n",
      "==================================================\n",
      "Processing Sample 67 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:44<00:00,  6.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 67 Scores:\n",
      "  Faithfulness             : 0.818\n",
      "  Answer Relevancy         : 0.894\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.449\n",
      "  Answer Similarity        : 0.937\n",
      "\n",
      "==================================================\n",
      "Processing Sample 68 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 68 Scores:\n",
      "  Faithfulness             : 0.800\n",
      "  Answer Relevancy         : 0.950\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.750\n",
      "  Answer Correctness       : 0.231\n",
      "  Answer Similarity        : 0.924\n",
      "\n",
      "==================================================\n",
      "Processing Sample 69 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:40<00:00,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 69 Scores:\n",
      "  Faithfulness             : 0.857\n",
      "  Answer Relevancy         : 0.976\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.572\n",
      "  Answer Similarity        : 0.956\n",
      "\n",
      "==================================================\n",
      "Processing Sample 70 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:17,  2.85s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:51<00:00,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 70 Scores:\n",
      "  Faithfulness             : 0.909\n",
      "  Answer Relevancy         : 0.969\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.464\n",
      "  Answer Similarity        : 0.933\n",
      "\n",
      "==================================================\n",
      "Processing Sample 71 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 71 Scores:\n",
      "  Faithfulness             : 0.941\n",
      "  Answer Relevancy         : 0.941\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.303\n",
      "  Answer Similarity        : 0.898\n",
      "\n",
      "==================================================\n",
      "Processing Sample 72 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  5.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 72 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.970\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.231\n",
      "  Answer Similarity        : 0.925\n",
      "\n",
      "==================================================\n",
      "Processing Sample 73 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:42<00:00,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 73 Scores:\n",
      "  Faithfulness             : 0.778\n",
      "  Answer Relevancy         : 0.992\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.382\n",
      "  Answer Similarity        : 0.958\n",
      "\n",
      "==================================================\n",
      "Processing Sample 74 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:17,  2.98s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 74 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.971\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.308\n",
      "  Answer Similarity        : 0.915\n",
      "\n",
      "==================================================\n",
      "Processing Sample 75 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:50<00:00,  7.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 75 Scores:\n",
      "  Faithfulness             : 0.933\n",
      "  Answer Relevancy         : 0.887\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.200\n",
      "  Answer Correctness       : 0.537\n",
      "  Answer Similarity        : 0.950\n",
      "\n",
      "==================================================\n",
      "Processing Sample 76 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:19,  3.23s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  5.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 76 Scores:\n",
      "  Faithfulness             : 0.917\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.651\n",
      "  Answer Similarity        : 0.936\n",
      "\n",
      "==================================================\n",
      "Processing Sample 77 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:40<00:00,  5.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 77 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.891\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.478\n",
      "  Answer Similarity        : 0.913\n",
      "\n",
      "==================================================\n",
      "Processing Sample 78 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:45<00:00,  6.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 78 Scores:\n",
      "  Faithfulness             : 0.933\n",
      "  Answer Relevancy         : 0.980\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.750\n",
      "  Answer Correctness       : 0.564\n",
      "  Answer Similarity        : 0.968\n",
      "\n",
      "==================================================\n",
      "Processing Sample 79 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  5.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 79 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.403\n",
      "  Answer Similarity        : 0.946\n",
      "\n",
      "==================================================\n",
      "Processing Sample 80 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  86%|████████▌ | 6/7 [00:58<00:08,  8.30s/it]Exception raised in Job[5]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 7/7 [03:00<00:00, 25.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 80 Scores:\n",
      "  Faithfulness             : 0.867\n",
      "  Answer Relevancy         : 0.986\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : 0.955\n",
      "\n",
      "==================================================\n",
      "Processing Sample 81 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:06<00:40,  6.73s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 81 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.983\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.317\n",
      "  Answer Similarity        : 0.893\n",
      "\n",
      "==================================================\n",
      "Processing Sample 82 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  5.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 82 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.956\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.544\n",
      "  Answer Similarity        : 0.974\n",
      "\n",
      "==================================================\n",
      "Processing Sample 83 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:16,  2.71s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:44<00:00,  6.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 83 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.241\n",
      "  Answer Similarity        : 0.962\n",
      "\n",
      "==================================================\n",
      "Processing Sample 84 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 84 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.911\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.344\n",
      "  Answer Similarity        : 0.947\n",
      "\n",
      "==================================================\n",
      "Processing Sample 85 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:17,  2.99s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 85 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.984\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.235\n",
      "  Answer Similarity        : 0.941\n",
      "\n",
      "==================================================\n",
      "Processing Sample 86 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:16,  2.68s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:42<00:00,  6.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 86 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.949\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.667\n",
      "  Answer Similarity        : 0.954\n",
      "\n",
      "==================================================\n",
      "Processing Sample 87 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 87 Scores:\n",
      "  Faithfulness             : 0.773\n",
      "  Answer Relevancy         : 0.968\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.405\n",
      "  Answer Similarity        : 0.929\n",
      "\n",
      "==================================================\n",
      "Processing Sample 88 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 88 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.844\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.330\n",
      "  Answer Similarity        : 0.892\n",
      "\n",
      "==================================================\n",
      "Processing Sample 89 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:18,  3.08s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:52<00:00,  7.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 89 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.991\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.363\n",
      "  Answer Similarity        : 0.931\n",
      "\n",
      "==================================================\n",
      "Processing Sample 90 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:47<00:00,  6.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 90 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.906\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.414\n",
      "  Answer Similarity        : 0.905\n",
      "\n",
      "==================================================\n",
      "Processing Sample 91 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 91 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.975\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.438\n",
      "  Answer Similarity        : 0.953\n",
      "\n",
      "==================================================\n",
      "Processing Sample 92 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:53<00:00,  7.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 92 Scores:\n",
      "  Faithfulness             : 0.947\n",
      "  Answer Relevancy         : 0.921\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.499\n",
      "  Answer Similarity        : 0.954\n",
      "\n",
      "==================================================\n",
      "Processing Sample 93 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 93 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.832\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.552\n",
      "  Answer Similarity        : 0.943\n",
      "\n",
      "==================================================\n",
      "Processing Sample 94 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:52<00:00,  7.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 94 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.829\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.305\n",
      "  Answer Similarity        : 0.920\n",
      "\n",
      "==================================================\n",
      "Processing Sample 95 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:12<01:14, 12.48s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:42<00:00,  6.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 95 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.600\n",
      "  Answer Correctness       : 0.544\n",
      "  Answer Similarity        : 0.977\n",
      "\n",
      "==================================================\n",
      "Processing Sample 96 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  29%|██▊       | 2/7 [00:11<00:26,  5.34s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:52<00:00,  7.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 96 Scores:\n",
      "  Faithfulness             : 0.789\n",
      "  Answer Relevancy         : 0.808\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.223\n",
      "  Answer Similarity        : 0.891\n",
      "\n",
      "==================================================\n",
      "Processing Sample 97 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:51<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 97 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.845\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.420\n",
      "  Answer Similarity        : 0.930\n",
      "\n",
      "==================================================\n",
      "Processing Sample 98 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 98 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.902\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.219\n",
      "  Answer Similarity        : 0.877\n",
      "\n",
      "==================================================\n",
      "Processing Sample 99 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:17,  2.88s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:44<00:00,  6.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 99 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.490\n",
      "  Answer Similarity        : 0.960\n",
      "\n",
      "==================================================\n",
      "Processing Sample 100 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:53<00:00,  7.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 100 Scores:\n",
      "  Faithfulness             : 0.500\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.746\n",
      "  Answer Similarity        : 0.983\n",
      "\n",
      "==================================================\n",
      "Processing Sample 101 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 101 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.912\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.200\n",
      "  Answer Correctness       : 0.325\n",
      "  Answer Similarity        : 0.925\n",
      "\n",
      "==================================================\n",
      "Processing Sample 102 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 102 Scores:\n",
      "  Faithfulness             : 0.917\n",
      "  Answer Relevancy         : 0.874\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.216\n",
      "  Answer Similarity        : 0.863\n",
      "\n",
      "==================================================\n",
      "Processing Sample 103 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [01:09<00:00,  9.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 103 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.961\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.301\n",
      "  Answer Similarity        : 0.931\n",
      "\n",
      "==================================================\n",
      "Processing Sample 104 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:17,  2.98s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 104 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.921\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.356\n",
      "  Answer Similarity        : 0.944\n",
      "\n",
      "==================================================\n",
      "Processing Sample 105 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:47<00:00,  6.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 105 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.890\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.167\n",
      "  Answer Correctness       : 0.653\n",
      "  Answer Similarity        : 0.944\n",
      "\n",
      "==================================================\n",
      "Processing Sample 106 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:07<00:42,  7.16s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 106 Scores:\n",
      "  Faithfulness             : 0.867\n",
      "  Answer Relevancy         : 0.921\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.484\n",
      "  Answer Similarity        : 0.937\n",
      "\n",
      "==================================================\n",
      "Processing Sample 107 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 107 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.936\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.563\n",
      "  Answer Similarity        : 0.917\n",
      "\n",
      "==================================================\n",
      "Processing Sample 108 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:59<00:00,  8.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 108 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.922\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.227\n",
      "  Answer Similarity        : 0.908\n",
      "\n",
      "==================================================\n",
      "Processing Sample 109 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:43<00:00,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 109 Scores:\n",
      "  Faithfulness             : 0.875\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.650\n",
      "  Answer Similarity        : 0.964\n",
      "\n",
      "==================================================\n",
      "Processing Sample 110 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:45<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 110 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.923\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.488\n",
      "  Answer Similarity        : 0.951\n",
      "\n",
      "==================================================\n",
      "Processing Sample 111 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:54<00:00,  7.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 111 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.901\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.444\n",
      "  Answer Correctness       : 0.742\n",
      "  Answer Similarity        : 0.968\n",
      "\n",
      "==================================================\n",
      "Processing Sample 112 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 112 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.962\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.522\n",
      "  Answer Similarity        : 0.963\n",
      "\n",
      "==================================================\n",
      "Processing Sample 113 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:55<00:00,  7.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 113 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.985\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.357\n",
      "  Answer Similarity        : 0.926\n",
      "\n",
      "==================================================\n",
      "Processing Sample 114 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:22,  3.69s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:45<00:00,  6.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 114 Scores:\n",
      "  Faithfulness             : 0.750\n",
      "  Answer Relevancy         : 0.965\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.346\n",
      "  Answer Similarity        : 0.954\n",
      "\n",
      "==================================================\n",
      "Processing Sample 115 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:47<00:00,  6.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 115 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.929\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.600\n",
      "  Answer Correctness       : 0.513\n",
      "  Answer Similarity        : 0.940\n",
      "\n",
      "==================================================\n",
      "Processing Sample 116 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:19,  3.29s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 116 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.978\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.534\n",
      "  Answer Similarity        : 0.936\n",
      "\n",
      "==================================================\n",
      "Processing Sample 117 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:12<01:13, 12.18s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:50<00:00,  7.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 117 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.940\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.490\n",
      "  Answer Similarity        : 0.962\n",
      "\n",
      "==================================================\n",
      "Processing Sample 118 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:05<00:33,  5.50s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:50<00:00,  7.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 118 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.919\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.358\n",
      "  Answer Similarity        : 0.933\n",
      "\n",
      "==================================================\n",
      "Processing Sample 119 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:07<00:42,  7.16s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:54<00:00,  7.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 119 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.993\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.355\n",
      "  Answer Similarity        : 0.959\n",
      "\n",
      "==================================================\n",
      "Processing Sample 120 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 120 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.844\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.235\n",
      "  Answer Similarity        : 0.939\n",
      "\n",
      "==================================================\n",
      "Processing Sample 121 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 121 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.988\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.398\n",
      "  Answer Similarity        : 0.960\n",
      "\n",
      "==================================================\n",
      "Processing Sample 122 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:58<00:00,  8.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 122 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.831\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.303\n",
      "  Answer Similarity        : 0.912\n",
      "\n",
      "==================================================\n",
      "Processing Sample 123 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:03<00:21,  3.60s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:44<00:00,  6.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 123 Scores:\n",
      "  Faithfulness             : 0.667\n",
      "  Answer Relevancy         : 0.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.468\n",
      "  Answer Similarity        : 0.949\n",
      "\n",
      "==================================================\n",
      "Processing Sample 124 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [01:07<00:00,  9.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 124 Scores:\n",
      "  Faithfulness             : 0.944\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.379\n",
      "  Answer Similarity        : 0.945\n",
      "\n",
      "==================================================\n",
      "Processing Sample 125 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:43<00:00,  6.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 125 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.966\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.228\n",
      "  Answer Similarity        : 0.910\n",
      "\n",
      "==================================================\n",
      "Processing Sample 126 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:49<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 126 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.208\n",
      "  Answer Similarity        : 0.833\n",
      "\n",
      "==================================================\n",
      "Processing Sample 127 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:52<00:00,  7.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 127 Scores:\n",
      "  Faithfulness             : 0.636\n",
      "  Answer Relevancy         : 0.987\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.636\n",
      "  Answer Similarity        : 0.943\n",
      "\n",
      "==================================================\n",
      "Processing Sample 128 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:12<01:16, 12.80s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:56<00:00,  8.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 128 Scores:\n",
      "  Faithfulness             : 0.920\n",
      "  Answer Relevancy         : 0.989\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.346\n",
      "  Answer Similarity        : 0.955\n",
      "\n",
      "==================================================\n",
      "Processing Sample 129 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [01:11<00:00, 10.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 129 Scores:\n",
      "  Faithfulness             : 0.889\n",
      "  Answer Relevancy         : 0.877\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.354\n",
      "  Answer Similarity        : 0.894\n",
      "\n",
      "==================================================\n",
      "Processing Sample 130 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 130 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.985\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.235\n",
      "  Answer Similarity        : 0.938\n",
      "\n",
      "==================================================\n",
      "Processing Sample 131 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:52<00:00,  7.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 131 Scores:\n",
      "  Faithfulness             : 0.800\n",
      "  Answer Relevancy         : 0.946\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.600\n",
      "  Answer Similarity        : 0.960\n",
      "\n",
      "==================================================\n",
      "Processing Sample 132 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:50<00:00,  7.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 132 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.913\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.750\n",
      "  Answer Correctness       : 0.381\n",
      "  Answer Similarity        : 0.925\n",
      "\n",
      "==================================================\n",
      "Processing Sample 133 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 133 Scores:\n",
      "  Faithfulness             : 0.857\n",
      "  Answer Relevancy         : 0.913\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.403\n",
      "  Answer Similarity        : 0.947\n",
      "\n",
      "==================================================\n",
      "Processing Sample 134 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:50<00:00,  7.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 134 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.944\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.750\n",
      "  Answer Correctness       : 0.538\n",
      "  Answer Similarity        : 0.910\n",
      "\n",
      "==================================================\n",
      "Processing Sample 135 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:44<00:00,  6.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 135 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.863\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.318\n",
      "  Answer Similarity        : 0.842\n",
      "\n",
      "==================================================\n",
      "Processing Sample 136 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:47<00:00,  6.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 136 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.925\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.361\n",
      "  Answer Similarity        : 0.899\n",
      "\n",
      "==================================================\n",
      "Processing Sample 137 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 137 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.968\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.363\n",
      "  Answer Similarity        : 0.951\n",
      "\n",
      "==================================================\n",
      "Processing Sample 138 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 138 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.833\n",
      "  Answer Correctness       : 0.836\n",
      "  Answer Similarity        : 0.944\n",
      "\n",
      "==================================================\n",
      "Processing Sample 139 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:13<01:22, 13.82s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 139 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.966\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.643\n",
      "  Answer Similarity        : 0.973\n",
      "\n",
      "==================================================\n",
      "Processing Sample 140 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:51<00:00,  7.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 140 Scores:\n",
      "  Faithfulness             : 0.947\n",
      "  Answer Relevancy         : 0.991\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.307\n",
      "  Answer Similarity        : 0.928\n",
      "\n",
      "==================================================\n",
      "Processing Sample 141 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:50<00:00,  7.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 141 Scores:\n",
      "  Faithfulness             : 0.583\n",
      "  Answer Relevancy         : 0.976\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.681\n",
      "  Answer Similarity        : 0.960\n",
      "\n",
      "==================================================\n",
      "Processing Sample 142 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:51<00:00,  7.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 142 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.993\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.274\n",
      "  Answer Similarity        : 0.894\n",
      "\n",
      "==================================================\n",
      "Processing Sample 143 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:16,  2.67s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:47<00:00,  6.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 143 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.000\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.231\n",
      "  Answer Similarity        : 0.924\n",
      "\n",
      "==================================================\n",
      "Processing Sample 144 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:54<00:00,  7.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 144 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.971\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.227\n",
      "  Answer Similarity        : 0.908\n",
      "\n",
      "==================================================\n",
      "Processing Sample 145 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:43<00:00,  6.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 145 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.994\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.999\n",
      "  Answer Similarity        : 0.997\n",
      "\n",
      "==================================================\n",
      "Processing Sample 146 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 146 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.934\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.335\n",
      "  Answer Similarity        : 0.940\n",
      "\n",
      "==================================================\n",
      "Processing Sample 147 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  71%|███████▏  | 5/7 [20:13<10:18, 309.38s/it]Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 7/7 [20:13<00:00, 173.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 147 Scores:\n",
      "  Faithfulness             : nan\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : 0.913\n",
      "\n",
      "==================================================\n",
      "Processing Sample 148 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]Exception raised in Job[1]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[4]: APIConnectionError(Connection error.)\n",
      "Evaluating:  14%|█▍        | 1/7 [00:01<00:10,  1.80s/it]Exception raised in Job[6]: APIConnectionError(Connection error.)\n",
      "Evaluating:  43%|████▎     | 3/7 [00:01<00:02,  1.98it/s]Exception raised in Job[3]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[0]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[2]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[5]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:01<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 148 Scores:\n",
      "  Faithfulness             : nan\n",
      "  Answer Relevancy         : nan\n",
      "  Context Precision        : nan\n",
      "  Context Recall           : nan\n",
      "  Context Entity Recall    : nan\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : nan\n",
      "\n",
      "==================================================\n",
      "Processing Sample 149 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]Exception raised in Job[1]: APIConnectionError(Connection error.)\n",
      "Evaluating:  14%|█▍        | 1/7 [00:01<00:08,  1.42s/it]Exception raised in Job[3]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[6]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[0]: APIConnectionError(Connection error.)\n",
      "Evaluating:  57%|█████▋    | 4/7 [00:01<00:00,  3.16it/s]Exception raised in Job[5]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[4]: APIConnectionError(Connection error.)\n",
      "Evaluating:  86%|████████▌ | 6/7 [00:01<00:00,  4.83it/s]Exception raised in Job[2]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:01<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 149 Scores:\n",
      "  Faithfulness             : nan\n",
      "  Answer Relevancy         : nan\n",
      "  Context Precision        : nan\n",
      "  Context Recall           : nan\n",
      "  Context Entity Recall    : nan\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : nan\n",
      "\n",
      "==================================================\n",
      "Processing Sample 150 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:48<00:00,  6.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 150 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.986\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.388\n",
      "  Answer Similarity        : 0.922\n",
      "\n",
      "==================================================\n",
      "Processing Sample 151 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  29%|██▊       | 2/7 [00:04<00:11,  2.31s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Exception raised in Job[1]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 151 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : nan\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.870\n",
      "  Answer Similarity        : 0.979\n",
      "\n",
      "==================================================\n",
      "Processing Sample 152 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.25s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:29<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 152 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.989\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.997\n",
      "  Answer Similarity        : 0.990\n",
      "\n",
      "==================================================\n",
      "Processing Sample 153 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.25s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  86%|████████▌ | 6/7 [00:26<00:03,  3.88s/it]Exception raised in Job[5]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:40<00:00,  5.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 153 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : 0.976\n",
      "\n",
      "==================================================\n",
      "Processing Sample 154 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]Exception raised in Job[6]: APIConnectionError(Connection error.)\n",
      "Evaluating:  14%|█▍        | 1/7 [00:01<00:07,  1.19s/it]Exception raised in Job[5]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[3]: APIConnectionError(Connection error.)\n",
      "Evaluating:  29%|██▊       | 2/7 [00:01<00:02,  1.81it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:18<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 154 Scores:\n",
      "  Faithfulness             : 0.833\n",
      "  Answer Relevancy         : 0.990\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : nan\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : nan\n",
      "\n",
      "==================================================\n",
      "Processing Sample 155 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:31<00:00,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 155 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.844\n",
      "  Answer Similarity        : 0.977\n",
      "\n",
      "==================================================\n",
      "Processing Sample 156 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:15,  2.50s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:36<00:00,  5.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 156 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.882\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.111\n",
      "  Answer Correctness       : 0.325\n",
      "  Answer Similarity        : 0.926\n",
      "\n",
      "==================================================\n",
      "Processing Sample 157 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.27s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  6.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 157 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.400\n",
      "  Answer Correctness       : 0.501\n",
      "  Answer Similarity        : 0.943\n",
      "\n",
      "==================================================\n",
      "Processing Sample 158 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.30s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:36<00:00,  5.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 158 Scores:\n",
      "  Faithfulness             : 0.800\n",
      "  Answer Relevancy         : 0.985\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.200\n",
      "  Answer Correctness       : 0.333\n",
      "  Answer Similarity        : 0.930\n",
      "\n",
      "==================================================\n",
      "Processing Sample 159 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.29s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  86%|████████▌ | 6/7 [00:30<00:04,  4.51s/it]Exception raised in Job[5]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:42<00:00,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 159 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.982\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : 0.892\n",
      "\n",
      "==================================================\n",
      "Processing Sample 160 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:37<00:00,  5.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 160 Scores:\n",
      "  Faithfulness             : 0.727\n",
      "  Answer Relevancy         : 0.968\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.229\n",
      "  Answer Similarity        : 0.917\n",
      "\n",
      "==================================================\n",
      "Processing Sample 161 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:14,  2.38s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:33<00:00,  4.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 161 Scores:\n",
      "  Faithfulness             : 0.375\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.223\n",
      "  Answer Similarity        : 0.892\n",
      "\n",
      "==================================================\n",
      "Processing Sample 162 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:14,  2.34s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:28<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 162 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.481\n",
      "  Answer Similarity        : 0.922\n",
      "\n",
      "==================================================\n",
      "Processing Sample 163 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.27s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:27<00:00,  3.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 163 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.995\n",
      "  Answer Similarity        : 0.981\n",
      "\n",
      "==================================================\n",
      "Processing Sample 164 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.31s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  43%|████▎     | 3/7 [00:16<00:24,  6.05s/it]Exception raised in Job[4]: APIConnectionError(Connection error.)\n",
      "Evaluating:  71%|███████▏  | 5/7 [00:23<00:09,  4.71s/it]Exception raised in Job[5]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[0]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:23<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 164 Scores:\n",
      "  Faithfulness             : nan\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : nan\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : 0.985\n",
      "\n",
      "==================================================\n",
      "Processing Sample 165 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]Exception raised in Job[6]: APIConnectionError(Connection error.)\n",
      "Evaluating:  14%|█▍        | 1/7 [00:01<00:07,  1.25s/it]Exception raised in Job[4]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[3]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[5]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[0]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[2]: APIConnectionError(Connection error.)\n",
      "Evaluating:  71%|███████▏  | 5/7 [00:01<00:00,  4.60it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:07<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 165 Scores:\n",
      "  Faithfulness             : nan\n",
      "  Answer Relevancy         : 0.933\n",
      "  Context Precision        : nan\n",
      "  Context Recall           : nan\n",
      "  Context Entity Recall    : nan\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : nan\n",
      "\n",
      "==================================================\n",
      "Processing Sample 166 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:39<00:00,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 166 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.739\n",
      "  Answer Similarity        : 0.955\n",
      "\n",
      "==================================================\n",
      "Processing Sample 167 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.25s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:28<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 167 Scores:\n",
      "  Faithfulness             : 0.700\n",
      "  Answer Relevancy         : 0.986\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.875\n",
      "  Answer Correctness       : 0.863\n",
      "  Answer Similarity        : 0.982\n",
      "\n",
      "==================================================\n",
      "Processing Sample 168 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.27s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:34<00:00,  4.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 168 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.982\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.857\n",
      "  Answer Correctness       : 0.860\n",
      "  Answer Similarity        : 0.967\n",
      "\n",
      "==================================================\n",
      "Processing Sample 169 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:14,  2.35s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:36<00:00,  5.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 169 Scores:\n",
      "  Faithfulness             : 0.800\n",
      "  Answer Relevancy         : 0.966\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.385\n",
      "  Answer Similarity        : 0.939\n",
      "\n",
      "==================================================\n",
      "Processing Sample 170 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:14,  2.35s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Exception raised in Job[1]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:34<00:00,  4.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 170 Scores:\n",
      "  Faithfulness             : 0.750\n",
      "  Answer Relevancy         : nan\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.441\n",
      "  Answer Similarity        : 0.963\n",
      "\n",
      "==================================================\n",
      "Processing Sample 171 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.26s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:40<00:00,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 171 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.989\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.850\n",
      "  Answer Similarity        : 0.929\n",
      "\n",
      "==================================================\n",
      "Processing Sample 172 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.29s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:30<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 172 Scores:\n",
      "  Faithfulness             : 0.800\n",
      "  Answer Relevancy         : 0.995\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.632\n",
      "  Answer Correctness       : 0.906\n",
      "  Answer Similarity        : 0.957\n",
      "\n",
      "==================================================\n",
      "Processing Sample 173 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.30s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:27<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 173 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.200\n",
      "  Answer Correctness       : 0.997\n",
      "  Answer Similarity        : 0.989\n",
      "\n",
      "==================================================\n",
      "Processing Sample 174 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:15,  2.55s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Exception raised in Job[1]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:41<00:00,  5.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 174 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : nan\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.468\n",
      "  Answer Similarity        : 0.925\n",
      "\n",
      "==================================================\n",
      "Processing Sample 175 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.31s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:28<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 175 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.424\n",
      "  Answer Similarity        : 0.948\n",
      "\n",
      "==================================================\n",
      "Processing Sample 176 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.30s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:31<00:00,  4.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 176 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.987\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.522\n",
      "  Answer Similarity        : 0.887\n",
      "\n",
      "==================================================\n",
      "Processing Sample 177 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:26<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 177 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.496\n",
      "  Answer Similarity        : 0.985\n",
      "\n",
      "==================================================\n",
      "Processing Sample 178 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.30s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:36<00:00,  5.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 178 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.868\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.800\n",
      "  Answer Correctness       : 0.609\n",
      "  Answer Similarity        : 0.938\n",
      "\n",
      "==================================================\n",
      "Processing Sample 179 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:14,  2.35s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:34<00:00,  4.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 179 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.995\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.871\n",
      "  Answer Similarity        : 0.983\n",
      "\n",
      "==================================================\n",
      "Processing Sample 180 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.25s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:28<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 180 Scores:\n",
      "  Faithfulness             : 0.600\n",
      "  Answer Relevancy         : 0.868\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.475\n",
      "  Answer Similarity        : 0.900\n",
      "\n",
      "==================================================\n",
      "Processing Sample 181 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:14,  2.41s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:35<00:00,  5.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 181 Scores:\n",
      "  Faithfulness             : 0.769\n",
      "  Answer Relevancy         : 0.980\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.429\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.354\n",
      "  Answer Similarity        : 0.917\n",
      "\n",
      "==================================================\n",
      "Processing Sample 182 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:14,  2.38s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  71%|███████▏  | 5/7 [00:17<00:06,  3.05s/it]Exception raised in Job[0]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:30<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 182 Scores:\n",
      "  Faithfulness             : nan\n",
      "  Answer Relevancy         : 0.994\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.311\n",
      "  Answer Similarity        : 0.912\n",
      "\n",
      "==================================================\n",
      "Processing Sample 183 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:14,  2.35s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:35<00:00,  5.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 183 Scores:\n",
      "  Faithfulness             : 0.667\n",
      "  Answer Relevancy         : 0.000\n",
      "  Context Precision        : 0.000\n",
      "  Context Recall           : 0.000\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.186\n",
      "  Answer Similarity        : 0.745\n",
      "\n",
      "==================================================\n",
      "Processing Sample 184 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.31s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:34<00:00,  4.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 184 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.750\n",
      "  Answer Correctness       : 0.846\n",
      "  Answer Similarity        : 0.985\n",
      "\n",
      "==================================================\n",
      "Processing Sample 185 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.31s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:31<00:00,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 185 Scores:\n",
      "  Faithfulness             : 0.125\n",
      "  Answer Relevancy         : 0.972\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.229\n",
      "  Answer Similarity        : 0.916\n",
      "\n",
      "==================================================\n",
      "Processing Sample 186 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.27s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Exception raised in Job[1]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:35<00:00,  5.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 186 Scores:\n",
      "  Faithfulness             : 0.286\n",
      "  Answer Relevancy         : nan\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.750\n",
      "  Answer Correctness       : 0.207\n",
      "  Answer Similarity        : 0.825\n",
      "\n",
      "==================================================\n",
      "Processing Sample 187 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  29%|██▊       | 2/7 [00:05<00:14,  2.87s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:36<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 187 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.927\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.667\n",
      "  Answer Correctness       : 0.221\n",
      "  Answer Similarity        : 0.885\n",
      "\n",
      "==================================================\n",
      "Processing Sample 188 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:17,  2.98s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Exception raised in Job[1]: APIConnectionError(Connection error.)\n",
      "Evaluating:  86%|████████▌ | 6/7 [00:33<00:05,  5.41s/it]Exception raised in Job[5]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:46<00:00,  6.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 188 Scores:\n",
      "  Faithfulness             : 0.938\n",
      "  Answer Relevancy         : nan\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : 0.953\n",
      "\n",
      "==================================================\n",
      "Processing Sample 189 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:39<00:00,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 189 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.971\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.125\n",
      "  Answer Correctness       : 0.450\n",
      "  Answer Similarity        : 0.943\n",
      "\n",
      "==================================================\n",
      "Processing Sample 190 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.29s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:34<00:00,  4.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 190 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.966\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.200\n",
      "  Answer Correctness       : 0.516\n",
      "  Answer Similarity        : 0.922\n",
      "\n",
      "==================================================\n",
      "Processing Sample 191 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:14,  2.48s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:36<00:00,  5.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 191 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 0.333\n",
      "  Answer Correctness       : 0.408\n",
      "  Answer Similarity        : 0.964\n",
      "\n",
      "==================================================\n",
      "Processing Sample 192 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.28s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  71%|███████▏  | 5/7 [00:17<00:07,  3.58s/it]Exception raised in Job[0]: APIConnectionError(Connection error.)\n",
      "Evaluating:  86%|████████▌ | 6/7 [00:24<00:04,  4.63s/it]Exception raised in Job[5]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:24<00:00,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 192 Scores:\n",
      "  Faithfulness             : nan\n",
      "  Answer Relevancy         : 0.951\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : 0.974\n",
      "\n",
      "==================================================\n",
      "Processing Sample 193 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]Exception raised in Job[0]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[1]: APIConnectionError(Connection error.)\n",
      "Evaluating:  14%|█▍        | 1/7 [00:01<00:07,  1.30s/it]Exception raised in Job[4]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[3]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[2]: APIConnectionError(Connection error.)\n",
      "Exception raised in Job[5]: APIConnectionError(Connection error.)\n",
      "Evaluating:  86%|████████▌ | 6/7 [00:01<00:00,  5.48it/s]Exception raised in Job[6]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:01<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 193 Scores:\n",
      "  Faithfulness             : nan\n",
      "  Answer Relevancy         : nan\n",
      "  Context Precision        : nan\n",
      "  Context Recall           : nan\n",
      "  Context Entity Recall    : nan\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : nan\n",
      "\n",
      "==================================================\n",
      "Processing Sample 194 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:27<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 194 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.943\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.000\n",
      "  Answer Correctness       : 0.646\n",
      "  Answer Similarity        : 0.949\n",
      "\n",
      "==================================================\n",
      "Processing Sample 195 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.28s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  71%|███████▏  | 5/7 [00:17<00:06,  3.05s/it]Exception raised in Job[5]: APIConnectionError(Connection error.)\n",
      "Evaluating: 100%|██████████| 7/7 [00:30<00:00,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 195 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.985\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : nan\n",
      "  Answer Similarity        : 0.950\n",
      "\n",
      "==================================================\n",
      "Processing Sample 196 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:31<00:00,  4.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 196 Scores:\n",
      "  Faithfulness             : 0.929\n",
      "  Answer Relevancy         : 1.000\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 0.250\n",
      "  Answer Correctness       : 0.413\n",
      "  Answer Similarity        : 0.945\n",
      "\n",
      "==================================================\n",
      "Processing Sample 197 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.30s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:40<00:00,  5.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 197 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.993\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.667\n",
      "  Context Entity Recall    : 0.500\n",
      "  Answer Correctness       : 0.404\n",
      "  Answer Similarity        : 0.948\n",
      "\n",
      "==================================================\n",
      "Processing Sample 198 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.32s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:32<00:00,  4.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 198 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.972\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 0.500\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.426\n",
      "  Answer Similarity        : 0.954\n",
      "\n",
      "==================================================\n",
      "Processing Sample 199 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.31s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:38<00:00,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 199 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.984\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.642\n",
      "  Answer Similarity        : 0.968\n",
      "\n",
      "==================================================\n",
      "Processing Sample 200 / 200\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▍        | 1/7 [00:02<00:13,  2.26s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 7/7 [00:34<00:00,  4.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 200 Scores:\n",
      "  Faithfulness             : 1.000\n",
      "  Answer Relevancy         : 0.990\n",
      "  Context Precision        : 1.000\n",
      "  Context Recall           : 1.000\n",
      "  Context Entity Recall    : 1.000\n",
      "  Answer Correctness       : 0.315\n",
      "  Answer Similarity        : 0.946\n",
      "\n",
      "==================================================\n",
      "Combining all results...\n",
      "==================================================\n",
      "Detailed results saved to evaluation_results.json\n",
      "Results exported to evaluation_results.csv\n",
      "Summary statistics saved to evaluation_summary.json\n",
      "\n",
      "==================================================\n",
      "RAGAS QUICK SUMMARY (Mean Scores)\n",
      "==================================================\n",
      "Faithfulness             : 0.926\n",
      "Answer Relevancy         : 0.921\n",
      "Context Precision        : 0.867\n",
      "Context Recall           : 0.687\n",
      "Context Entity Recall    : 0.423\n",
      "Answer Correctness       : 0.452\n",
      "Answer Similarity        : 0.939\n",
      "==================================================\n",
      "\n",
      " ✅ Evaluation completed successfully!\n",
      "Total successful samples evaluated: 200\n",
      "\n",
      "First 3 results preview:\n",
      "================================================================================\n",
      "\n",
      "Sample 1:\n",
      "Question (Start): N/A...\n",
      "Faithfulness: 0.923\n",
      "Answer Relevancy: 0.975\n",
      "Context Precision: 1.000\n",
      "Context Recall: 1.000\n",
      "Context Entity Recall: 0.333\n",
      "Answer Correctness: 0.429\n",
      "Answer Similarity: 0.964\n",
      "----------------------------------------\n",
      "\n",
      "Sample 2:\n",
      "Question (Start): N/A...\n",
      "Faithfulness: 1.000\n",
      "Answer Relevancy: 0.983\n",
      "Context Precision: 1.000\n",
      "Context Recall: 1.000\n",
      "Context Entity Recall: 0.667\n",
      "Answer Correctness: 0.311\n",
      "Answer Similarity: 0.959\n",
      "----------------------------------------\n",
      "\n",
      "Sample 3:\n",
      "Question (Start): N/A...\n",
      "Faithfulness: 1.000\n",
      "Answer Relevancy: 0.955\n",
      "Context Precision: 1.000\n",
      "Context Recall: 1.000\n",
      "Context Entity Recall: 1.000\n",
      "Answer Correctness: 0.579\n",
      "Answer Similarity: 0.983\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- This is the main execution block ---\n",
    "# (Note: We remove the 'if __name__ == \"__main__\":' check for notebooks)\n",
    "\n",
    "results_df = None\n",
    "summary_stats = {}\n",
    "\n",
    "# ⚠️ Set the path to your data file\n",
    "# This path was from your original script. Update it if needed.\n",
    "json_file_path = \"200_sample_test_qa_eval.jsonl\"\n",
    "\n",
    "try:\n",
    "    print(f\"Starting iterative evaluation for: {json_file_path}\")\n",
    "    \n",
    "    results_df = evaluate_dataset_iteratively(json_file_path)\n",
    "    \n",
    "    if results_df is not None and not results_df.empty:\n",
    "        # Save all results\n",
    "        save_results(results_df)\n",
    "        export_to_csv(results_df)\n",
    "        \n",
    "        # Create and print summary\n",
    "        summary_stats = create_summary_statistics(results_df)\n",
    "        print_quick_summary(summary_stats)\n",
    "        \n",
    "        print(\"\\n ✅ Evaluation completed successfully!\")\n",
    "        print(f\"Total successful samples evaluated: {len(results_df)}\")\n",
    "\n",
    "        print(\"\\nFirst 3 results preview:\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Display the start of the question in the preview\n",
    "        for i in range(min(3, len(results_df))):\n",
    "            result = results_df.iloc[i]\n",
    "            print(f\"\\nSample {i+1}:\")\n",
    "            \n",
    "            # Get the question and limit it to the first 100 characters for a preview\n",
    "            question_preview = result.get('question', 'N/A')\n",
    "            print(f\"Question (Start): {question_preview[:100]}...\")\n",
    "            \n",
    "            for metric in REQUESTED_METRICS:\n",
    "                score = result.get(metric.name, 'N/A')\n",
    "                if isinstance(score, float):\n",
    "                    score = f\"{score:.3f}\"\n",
    "                print(f\"{metric.name.replace('_', ' ').title()}: {score}\")\n",
    "            \n",
    "            print(\"-\" * 40)\n",
    "\n",
    "    else:\n",
    "        print(\"Evaluation did not produce any successful results.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ File not found: {e}\")\n",
    "    print(f\"Please check if the file exists at: {json_file_path}\")\n",
    "\n",
    "except RagasException as e:\n",
    "    print(f\"\\n❌ [RAGAS ERROR] {e}\")\n",
    "    print(\"Evaluation halted. Check API keys, endpoints, and rate limits.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Unexpected error in main execution: {e}\")\n",
    "    print(f\"Full traceback:\\n{traceback.format_exc()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
